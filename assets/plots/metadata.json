{"plots": [{"name": "influence_age", "description": "We can plot the average output of a model relatively to the average value of a feature. Here, we can see that, on average, the older the richer until a certain limit. From about 50 year-old, the older the poorer, which probably reflects the fact that people are about to retire so companies don't especially want to invest in them."}, {"name": "influence_multiple_features", "description": "We can plot the influence of multiple features. The x axis represents the quantiles: -1 is 5%, 0 is the original mean and 1 is 95%."}, {"name": "influence_ranking", "description": "We can rank the features by their influence on the model. Intuitively, a feature with no influence is an horizontal line <code>y = original mean</code>. To measure its influence, we compute the average distance to this reference line."}, {"name": "influence_comparison", "description": "We can compare two individuals by looking at how the model would behave if the average individual of the dataset was different. On the left, we can see that people having Mary's age are on average 12.8% more likely to earn more than $50k a year than people with Bob's age. On the opposite, we can unfortunately see that Mary's gender is not helping her compared to Bob."}, {"name": "performance_age", "description": "We can visualize how the model's performance changes with the average value of a feature. Here, we can see that the model performs worse for older people, so we are probably lacking such data samples."}, {"name": "stressed_distributions", "description": "As explained in the paper, we stress the probability distribution to obtain a different mean while minimizing the Kullback-Leibler divergence with the original distribution. We can visualize the stressed distributions."}, {"name": "influence_image", "description": "For images, we can visualize the influence of the pixels on the output."}]}