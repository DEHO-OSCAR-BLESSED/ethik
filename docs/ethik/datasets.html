<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.6.3" />
<title>ethik.datasets API documentation</title>
<meta name="description" content="" />
<link href='https://cdnjs.cloudflare.com/ajax/libs/normalize/8.0.0/normalize.min.css' rel='stylesheet'>
<link href='https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/8.0.0/sanitize.min.css' rel='stylesheet'>
<link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" rel="stylesheet">
<style>.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{font-weight:bold}#index h4 + ul{margin-bottom:.6em}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase;cursor:pointer}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>ethik.datasets</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>Source code</summary>
<pre><code class="python">import os

import pandas as pd

__all__ = [&#34;load_law_school&#34;]


def load_law_school():
    &#34;&#34;&#34;Law school admission data.

    The Law School Admission Council conducted a survey across 163 law schools in the United
    States. It contains information on 21,790 law students such as their entrance exam scores
    (LSAT), their grade-point average (GPA) collected prior to law school, and their first year
    average grade (FYA).

    Given this data, a school may wish to predict if an applicant will have a high FYA. The school
    would also like to make sure these predictions are not biased by an individual’s race and sex.
    However, the LSAT, GPA, and FYA scores, may be biased due to social factors.

    Example:

        &gt;&gt;&gt; import ethik

        &gt;&gt;&gt; X, y = ethik.datasets.load_law_school()

        &gt;&gt;&gt; X.head(10)
                race     sex  LSAT  UGPA region_first  ZFYA  sander_index
        0      White  Female  39.0   3.1           GL -0.98      0.782738
        1      White  Female  36.0   3.0           GL  0.09      0.735714
        2      White    Male  30.0   3.1           MS -0.35      0.670238
        5   Hispanic    Male  39.0   2.2           NE  0.58      0.697024
        6      White  Female  37.0   3.4           GL -1.26      0.786310
        7      White  Female  30.5   3.6           GL  0.30      0.724107
        8      White    Male  36.0   3.6           GL -0.10      0.792857
        9      White    Male  37.0   2.7           NE -0.12      0.719643
        13     White  Female  37.0   2.6           GL  1.53      0.710119
        14     White    Male  31.0   3.6           GL  0.34      0.730357

        &gt;&gt;&gt; y.head(10)
        0      True
        1      True
        2      True
        5      True
        6      True
        7      True
        8      True
        9     False
        13     True
        14     True
        Name: first_pf, dtype: bool

    References:
        1. https://papers.nips.cc/paper/6995-counterfactual-fairness.pdf
        2. https://github.com/mkusner/counterfactual-fairness

    &#34;&#34;&#34;
    X = pd.read_csv(
        os.path.join(os.path.dirname(__file__), &#34;data&#34;, &#34;law_data.csv&#34;),
        dtype={&#34;race&#34;: &#34;category&#34;, &#34;region_first&#34;: &#34;category&#34;},
        index_col=0
    )
    X[&#34;sex&#34;] = X[&#34;sex&#34;].map({1: &#34;Female&#34;, 2: &#34;Male&#34;}).astype(&#34;category&#34;)
    y = X.pop(&#34;first_pf&#34;).apply(int).astype(bool)
    return X, y</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="ethik.datasets.load_law_school"><code class="name flex">
<span>def <span class="ident">load_law_school</span></span>(<span>)</span>
</code></dt>
<dd>
<section class="desc"><p>Law school admission data.</p>
<p>The Law School Admission Council conducted a survey across 163 law schools in the United
States. It contains information on 21,790 law students such as their entrance exam scores
(LSAT), their grade-point average (GPA) collected prior to law school, and their first year
average grade (FYA).</p>
<p>Given this data, a school may wish to predict if an applicant will have a high FYA. The school
would also like to make sure these predictions are not biased by an individual’s race and sex.
However, the LSAT, GPA, and FYA scores, may be biased due to social factors.</p>
<h2 id="example">Example</h2>
<pre><code>&gt;&gt;&gt; import ethik

&gt;&gt;&gt; X, y = ethik.datasets.load_law_school()

&gt;&gt;&gt; X.head(10)
        race     sex  LSAT  UGPA region_first  ZFYA  sander_index
</code></pre>
<p>0
White
Female
39.0
3.1
GL -0.98
0.782738
1
White
Female
36.0
3.0
GL
0.09
0.735714
2
White
Male
30.0
3.1
MS -0.35
0.670238
5
Hispanic
Male
39.0
2.2
NE
0.58
0.697024
6
White
Female
37.0
3.4
GL -1.26
0.786310
7
White
Female
30.5
3.6
GL
0.30
0.724107
8
White
Male
36.0
3.6
GL -0.10
0.792857
9
White
Male
37.0
2.7
NE -0.12
0.719643
13
White
Female
37.0
2.6
GL
1.53
0.710119
14
White
Male
31.0
3.6
GL
0.34
0.730357</p>
<pre><code>&gt;&gt;&gt; y.head(10)
0      True
</code></pre>
<dl>
<dt>1
True</dt>
<dt>2
True</dt>
<dt>5
True</dt>
<dt>6
True</dt>
<dt>7
True</dt>
<dt>8
True</dt>
<dt>9
False</dt>
<dt>13
True</dt>
<dt>14
True</dt>
<dt><strong><code>Name</code></strong></dt>
<dd>first_pf, dtype: bool</dd>
</dl>
<h2 id="references">References</h2>
<ol>
<li><a href="https://papers.nips.cc/paper/6995-counterfactual-fairness.pdf">https://papers.nips.cc/paper/6995-counterfactual-fairness.pdf</a></li>
<li><a href="https://github.com/mkusner/counterfactual-fairness">https://github.com/mkusner/counterfactual-fairness</a></li>
</ol></section>
<details class="source">
<summary>Source code</summary>
<pre><code class="python">def load_law_school():
    &#34;&#34;&#34;Law school admission data.

    The Law School Admission Council conducted a survey across 163 law schools in the United
    States. It contains information on 21,790 law students such as their entrance exam scores
    (LSAT), their grade-point average (GPA) collected prior to law school, and their first year
    average grade (FYA).

    Given this data, a school may wish to predict if an applicant will have a high FYA. The school
    would also like to make sure these predictions are not biased by an individual’s race and sex.
    However, the LSAT, GPA, and FYA scores, may be biased due to social factors.

    Example:

        &gt;&gt;&gt; import ethik

        &gt;&gt;&gt; X, y = ethik.datasets.load_law_school()

        &gt;&gt;&gt; X.head(10)
                race     sex  LSAT  UGPA region_first  ZFYA  sander_index
        0      White  Female  39.0   3.1           GL -0.98      0.782738
        1      White  Female  36.0   3.0           GL  0.09      0.735714
        2      White    Male  30.0   3.1           MS -0.35      0.670238
        5   Hispanic    Male  39.0   2.2           NE  0.58      0.697024
        6      White  Female  37.0   3.4           GL -1.26      0.786310
        7      White  Female  30.5   3.6           GL  0.30      0.724107
        8      White    Male  36.0   3.6           GL -0.10      0.792857
        9      White    Male  37.0   2.7           NE -0.12      0.719643
        13     White  Female  37.0   2.6           GL  1.53      0.710119
        14     White    Male  31.0   3.6           GL  0.34      0.730357

        &gt;&gt;&gt; y.head(10)
        0      True
        1      True
        2      True
        5      True
        6      True
        7      True
        8      True
        9     False
        13     True
        14     True
        Name: first_pf, dtype: bool

    References:
        1. https://papers.nips.cc/paper/6995-counterfactual-fairness.pdf
        2. https://github.com/mkusner/counterfactual-fairness

    &#34;&#34;&#34;
    X = pd.read_csv(
        os.path.join(os.path.dirname(__file__), &#34;data&#34;, &#34;law_data.csv&#34;),
        dtype={&#34;race&#34;: &#34;category&#34;, &#34;region_first&#34;: &#34;category&#34;},
        index_col=0
    )
    X[&#34;sex&#34;] = X[&#34;sex&#34;].map({1: &#34;Female&#34;, 2: &#34;Male&#34;}).astype(&#34;category&#34;)
    y = X.pop(&#34;first_pf&#34;).apply(int).astype(bool)
    return X, y</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="ethik" href="index.html">ethik</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="ethik.datasets.load_law_school" href="#ethik.datasets.load_law_school">load_law_school</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.6.3</a>.</p>
</footer>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
<script>hljs.initHighlightingOnLoad()</script>
</body>
</html>