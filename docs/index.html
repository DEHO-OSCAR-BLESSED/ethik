---
head: |
  <style>
    .header {
      text-align: center;
      padding: 50px 20px 20px 20px;
    }

    .header .plots {
      display: flex;
      justify-content: space-around;
    }

    .header .plots > div {
      height: 300px;
    }

    .header .plots .modebar {
      display: none;
    }

    .content {
      padding: 20px;
      max-width: 800px;
      margin: auto;
    }
  </style>
js: |
  <script src="https://cdn.plot.ly/plotly-latest.min.js"></script>
  <script>
    (function() {
      for (var id of ["header-plot-left", "header-plot-right"]) {
        (function(id) {
          var baseUrl = ""; // TODO
          var dataUrl = "assets/plots/" + id + ".json";
          fetch(baseUrl + dataUrl)
          .then(function(resp) {
            return resp.json();
          })
          .then(function(json) {
            Plotly.plot(document.getElementById(id), json.data, json.layout);
          });
        })(id);
      }
    })();
  </script>
---

<div class="header mdl-color--accent">
  <h1 class="mdl-typography ethik-font">
    Ethik AI
  </h1>
  <h2 class="mdl-typography--display-1 mdl-typography--font-light">
    A Python package for AI fairness and interpretability.
  </h2>

  <div class="plots">
    <div id="header-plot-left"></div>
    <div id="header-plot-right"></div>
  </div>
</div>

<div class="content">
  <p class="introduction">
    <code>ethik</code> is a Python package for performing <a href="https://perso.math.univ-toulouse.fr/loubes/fairness-robustness-in-machine-learning/">fair</a> and <a href="https://www.wikiwand.com/en/Explainable_artificial_intelligence">explainable</a> machine learning. At it's core, the approach of <code>ethik</code> is to build <strong>counterfactual distributions</strong> that permit answering "what if?" scenarios. The idea is that we are able to stress one or more variables and observe how a machine learning model reacts to the stress. The stress is based on a statistical re-weighting scheme called <strong>entropic variable projection</strong>. The main benefit of our method is that it will only consider realistic scenarios, and will not build fake examples. You may find more information by reading <a href="https://arxiv.org/abs/1810.07924">this paper</a> as well as the <a href="{{ "/tutorials/binary-classification" |Â relative_url }}">Get started</a> tutorial.
  </p>

<div align="center">
  <img src="{{ "/assets/img/overview.svg" | relative_url }}" width="660px" alt="overview"/>
</div>

  <p>
    Currently, <code>ethik</code> can be used for:
  </p>

  <ol>
    <li>Detecting model influence with respect to one or more (protected) attributes.</li>
    <li>Identifying causes for why a model performs poorly on certain inputs.</li>
    <li>Visualizing regions of an image that influence a model's predictions.</li>
  </ol>

  <p>
    We have more plans for the future.
  </p>

  <a href="{{ "/ai-fairness-and-interpretability" | relative_url }}">Learn more about AI fairness and interpretability</a>

  <h3 class="mdl-typography--display-1 mdl-typography--font-light">
    Understand our method
  </h3>

  <a href="{{ "/how-it-works" | relative_url }}">Learn more about our method</a>

  <h3 class="mdl-typography--display-1 mdl-typography--font-light">
    Use our package
  </h3>

  <h3 id="about" class="mdl-typography--display-1 mdl-typography--font-light">
    About
  </h3>
</div>
